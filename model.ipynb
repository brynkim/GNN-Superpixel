{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Sequential, GATConv, global_mean_pool\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar = True, nb_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type = str, default = 'Cora')\n",
    "parser.add_argument('--hidden_channels', type = int, default = 8)\n",
    "parser.add_argument('--heads', type = int, default = 8)\n",
    "parser.add_argument('--lr', type = float, default = 0.005)\n",
    "parser.add_argument('--weight_decay', type = float, default = 0.0)\n",
    "parser.add_argument('--epochs', type = int, default = 10)\n",
    "parser.add_argument('--wandb', action = 'store_true', help = 'Track experiment')\n",
    "parser.add_argument('--superpixel', type = str, default = 'slic')\n",
    "parser.add_argument('--image', type = str, default = 'rgb')\n",
    "parser.add_argument('--batch_size', type = int, default = 16)\n",
    "args = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./checkpoint/train_df.pickle', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "with open('./checkpoint/valid_df.pickle', 'rb') as f:\n",
    "    valid_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = pd.read_csv('./select.csv', delimiter = ',')\n",
    "selected_df['id'] = range(len(selected_df))\n",
    "selected_df = selected_df.loc[:4]                 # HACK: Limit the number for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2id = {directory: id for directory, id in zip(selected_df['directory'], selected_df['id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Import train data')\n",
    "dfs = []\n",
    "\n",
    "for filename in tqdm(os.listdir('./filtered/train')):\n",
    "    df = pd.read_pickle(f'./filtered/train/{filename}')\n",
    "    df = df[df['label'].apply(lambda x : x in class2id.keys())]\n",
    "    df['label'] = df['label'].apply(lambda x : class2id[x])\n",
    "    df = df[[f'{args.superpixel}_{args.image}_global_graph', f'{args.superpixel}_{args.image}', f'{args.image}', 'label']]\n",
    "    df.columns = ['graph', 'superpixel', 'image', 'label']\n",
    "    dfs.append(df)\n",
    "\n",
    "train_df = pd.concat(dfs).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Import validation data')\n",
    "dfs = []\n",
    "\n",
    "for filename in tqdm(os.listdir('./filtered/val')):\n",
    "    df = pd.read_pickle(f'./filtered/val/{filename}')\n",
    "    df = df[df['label'].apply(lambda x : x in class2id.keys())]\n",
    "    df['label'] = df['label'].apply(lambda x : class2id[x])\n",
    "    df = df[[f'{args.superpixel}_{args.image}_global_graph', f'{args.superpixel}_{args.image}', f'{args.image}', 'label']]\n",
    "    df.columns = ['graph', 'superpixel', 'image', 'label']\n",
    "    dfs.append(df)\n",
    "\n",
    "valid_df = pd.concat(dfs).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('./checkpoint/train_df.pickle')\n",
    "valid_df.to_pickle('./checkpoint/valid_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = valid_df['label'].max() + 1\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supix_statistics(data):\n",
    "    graph = data['graph']\n",
    "    superpixel = data['superpixel']\n",
    "    image = data['image']\n",
    "    label = data['label']\n",
    "    num_superpixel = data['superpixel'].max()\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "    centroids = []\n",
    "\n",
    "    for supix in range(superpixel.max() + 1):\n",
    "        mask = superpixel != supix      # Mask out the pixels that are not equal to given superpixel label.\n",
    "        trinary_mask = np.stack([mask, mask, mask], axis = 2)\n",
    "\n",
    "        masked = np.ma.masked_array(image, trinary_mask)\n",
    "        mean = np.ma.mean(masked, axis = (0, 1))\n",
    "        std = np.ma.std(masked, axis = (0, 1))\n",
    "        centroid = np.array([np.mean(subset) for subset in np.nonzero(np.logical_not(mask))])\n",
    "\n",
    "        means.append(mean.data)\n",
    "        stds.append(std.data)\n",
    "        centroids.append(centroid)\n",
    "\n",
    "    return means, stds, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute statistics for train data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861c3dc874ff4447927e6229e55acec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1625), Label(value='0 / 1625'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Compute statistics for train data')\n",
    "ret = train_df.parallel_apply(get_supix_statistics, axis = 1)\n",
    "train_df['means'] = [r[0] for r in ret]\n",
    "train_df['stds'] = [r[1] for r in ret]\n",
    "train_df['centroids'] = [r[2] for r in ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute statistics for validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:21<00:00, 11.63it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Compute statistics for validation data')\n",
    "ret = valid_df.progress_apply(get_supix_statistics, axis = 1)\n",
    "valid_df['means'] = [r[0] for r in ret]\n",
    "valid_df['stds'] = [r[1] for r in ret]\n",
    "valid_df['centroids'] = [r[2] for r in ret]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTRUCT NODE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/work/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "visual_model = torch.hub.load('chenyaofo/pytorch-cifar-models', 'cifar10_resnet20', pretrained = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_convolution_features(data):\n",
    "    graph = data['graph']\n",
    "    superpixel = data['superpixel']\n",
    "    image = data['image']\n",
    "    label = data['label']\n",
    "    num_superpixels = graph.number_of_nodes()\n",
    "    \n",
    "    masks = np.stack([superpixel == i for i in range(num_superpixels)])\n",
    "    masked_images = np.stack([image * np.expand_dims(mask, axis = -1) for mask in masks])\n",
    "    masked_images.shape\n",
    "    masked_images = masked_images.transpose(0, 3, 1, 2)\n",
    "    masked_images = masked_images / 255\n",
    "    masked_images = torch.tensor(masked_images).float().to(device)\n",
    "    \n",
    "    return visual_model(masked_images).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_node_features(data):\n",
    "    graph = data['graph']\n",
    "    means = data['means']\n",
    "    stds = data['stds']\n",
    "    centroids = data['centroids']\n",
    "    conv_features = data['conv_features']\n",
    "    weights = dict()\n",
    "\n",
    "    for index, (mean, std, centroid, conv_feature) in enumerate(zip(means, stds, centroids, conv_features)):\n",
    "        weight = np.concatenate([mean, std, centroid, conv_feature])\n",
    "        weights[index] = weight\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_new_graph(data):\n",
    "    graph = data['graph']\n",
    "    attribute = data['attributes']\n",
    "    for node in graph.nodes():\n",
    "        graph.nodes[node].clear()\n",
    "    nx.set_node_attributes(graph, attribute, name = 'features')\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_label(data):\n",
    "    G = data['graph']\n",
    "    label = data['label']\n",
    "\n",
    "    D = from_networkx(G, group_node_attrs = ['features'])\n",
    "    D['y'] = torch.tensor(label)\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6500/6500 [00:00<00:00, 412456.71it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 387071.24it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Filter graphs')\n",
    "train_df = train_df[train_df['graph'].progress_apply(lambda x : x.number_of_nodes() != 0)]\n",
    "valid_df = valid_df[valid_df['graph'].progress_apply(lambda x : x.number_of_nodes() != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct convolutional features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915702aca16d4af98ec3a86b672582a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1622), Label(value='0 / 1622'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Construct convolutional features')\n",
    "train_df['conv_features'] = train_df.parallel_apply(construct_convolution_features, axis = 1)\n",
    "valid_df['conv_features'] = valid_df.progress_apply(construct_convolution_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Construct node features')\n",
    "train_df['attributes'] = train_df.progress_apply(construct_node_features, axis = 1)\n",
    "valid_df['attributes'] = valid_df.progress_apply(construct_node_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Construct graphs')\n",
    "train_df['graph'] = train_df.progress_apply(construct_new_graph, axis = 1)\n",
    "valid_df['graph'] = valid_df.progress_apply(construct_new_graph, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build tensor data')\n",
    "train_df['data'] = train_df.progress_apply(attach_label, axis = 1)\n",
    "valid_df['data'] = valid_df.progress_apply(attach_label, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageNetDataset(InMemoryDataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(ImageNetDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "        self.data, self.slices = self.collate(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPINCS(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super(SPINCS, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout = 0.5)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads, dropout = 0.5)\n",
    "        self.linear = nn.Linear(hidden_channels * heads, out_channels)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p = 0.5, training = self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p = 0.5, training = self.training)\n",
    "        x = self.linear(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageNetDataset(train_df['data'].to_list())\n",
    "valid_dataset = ImageNetDataset(valid_df['data'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle = True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = args.batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SPINCS(18, args.hidden_channels, num_classes, args.heads).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr, weight_decay = args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train start!')\n",
    "for epoch in range(args.epochs):\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_correct = 0\n",
    "    train_size = 0\n",
    "\n",
    "    for data in train_dataloader:\n",
    "        x = data.x.float().to(device)\n",
    "        edge_index = data.edge_index.long().to(device)\n",
    "        batch = data.batch.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, edge_index, batch)\n",
    "        pred = output.argmax(axis = 1).cpu()\n",
    "\n",
    "        loss = criterion(output, F.one_hot(data.y, num_classes = num_classes).float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += (pred == data.y).sum()\n",
    "        train_size += data.y.shape[0]\n",
    "\n",
    "    train_loss = train_loss / train_size\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc = train_correct / train_size\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # Eval Mode\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    valid_correct = 0\n",
    "    valid_size = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in valid_dataloader:\n",
    "            x = data.x.float().to(device)\n",
    "            edge_index = data.edge_index.long().to(device)\n",
    "            batch = data.batch.long().to(device)\n",
    "\n",
    "            output = model(x, edge_index, batch)\n",
    "            pred = output.argmax(axis = 1).cpu()\n",
    "\n",
    "            loss = criterion(output, F.one_hot(data.y, num_classes = num_classes).float().to(device))\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_correct += (pred == data.y).sum()\n",
    "            valid_size += data.y.shape[0]\n",
    "\n",
    "        valid_loss = valid_loss / valid_size\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_acc = valid_correct / valid_size\n",
    "        valid_accs.append(valid_acc)\n",
    "\n",
    "    models.append(model)\n",
    "    print(f'Epoch {epoch} finished: train loss - {train_loss}, train acc - {train_acc} / valid loss - {valid_loss}, valid acc - {valid_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models.pkl', 'w') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_losses.pkl', 'w') as f:\n",
    "    pickle.dump(train_losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./valid_losses.pkl', 'w') as f:\n",
    "    pickle.dump(valid_losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dongjae_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c699c477c5c471d47a8de7a9cc4729800768f3401aa4bd1bfce7df4275c2064e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
