{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "import argparse\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Sequential, GATConv\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type = str, default = 'Cora')\n",
    "parser.add_argument('--hidden_channels', type = int, default = 8)\n",
    "parser.add_argument('--heads', type = int, default = 8)\n",
    "parser.add_argument('--lr', type = float, default = 0.005)\n",
    "parser.add_argument('--epochs', type = int, default = 200)\n",
    "parser.add_argument('--wandb', action = 'store_true', help = 'Track experiment')\n",
    "parser.add_argument('--superpixel', type = str, default = 'slic')\n",
    "parser.add_argument('--image', type = str, default = 'rgb')\n",
    "args = parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = pd.read_csv('./select.csv', delimiter = ',')\n",
    "selected_df['id'] = range(len(selected_df))\n",
    "selected_df = selected_df.loc[:5]                 # HACK: Limit the number for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2id = {directory: id for directory, id in zip(selected_df['directory'], selected_df['id'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [09:34<00:00,  5.74s/it]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for filename in tqdm(os.listdir('./filtered/train')):\n",
    "    df = pd.read_pickle(f'./filtered/train/{filename}')\n",
    "    df = df[df['label'].apply(lambda x : x in class2id.keys())]\n",
    "    df['label'] = df['label'].apply(lambda x : class2id[x])\n",
    "    df = df[[f'{args.superpixel}_{args.image}_global_graph', f'{args.superpixel}_{args.image}', f'{args.image}', 'label']]\n",
    "    df.columns = ['graph', 'superpixel', 'image', 'label']\n",
    "    dfs.append(df)\n",
    "\n",
    "train_df = pd.concat(dfs).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for filename in tqdm(os.listdir('./filtered/val')):\n",
    "    df = pd.read_pickle(f'./filtered/val/{filename}')\n",
    "    df = df[df['label'].apply(lambda x : x in class2id.keys())]\n",
    "    df['label'] = df['label'].apply(lambda x : class2id[x])\n",
    "    df = df[[f'{args.superpixel}_{args.image}_global_graph', f'{args.superpixel}_{args.image}', f'{args.image}', 'label']]\n",
    "    df.columns = ['graph', 'superpixel', 'image', 'label']\n",
    "    dfs.append(df)\n",
    "\n",
    "valid_df = pd.concat(dfs).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = train_df['label'].max()\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_supix_statistics(data):\n",
    "    graph = data['graph']\n",
    "    superpixel = data['superpixel']\n",
    "    image = data['image']\n",
    "    label = data['label']\n",
    "    num_superpixel = data['superpixel'].max()\n",
    "\n",
    "    means = []\n",
    "    stds = []\n",
    "    centroids = []\n",
    "\n",
    "    for supix in range(superpixel.max()):\n",
    "        mask = superpixel != supix      # Mask out the pixels that are not equal to given superpixel label.\n",
    "        trinary_mask = np.stack([mask, mask, mask], axis = 2)\n",
    "\n",
    "        masked = np.ma.masked_array(image, trinary_mask)\n",
    "        mean = np.ma.mean(masked, axis = (0, 1))\n",
    "        std = np.ma.std(masked, axis = (0, 1))\n",
    "        centroid = np.array([np.mean(subset) for subset in np.nonzero(np.logical_not(mask))])\n",
    "\n",
    "        means.append(mean.data)\n",
    "        stds.append(std.data)\n",
    "        centroids.append(centroid)\n",
    "\n",
    "    return means, stds, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = df.progress_apply(get_supix_statistics, axis = 1)\n",
    "df['means'] = [r[0] for r in ret]\n",
    "df['stds'] = [r[1] for r in ret]\n",
    "df['centroids'] = [r[2] for r in ret]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSTRUCT NODE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_node_features(data):\n",
    "    graph = data['graph']\n",
    "    means = data['means']\n",
    "    stds = data['stds']\n",
    "    centroids = data['centroids']\n",
    "    weights = dict()\n",
    "\n",
    "    for index, (mean, std, centroid) in enumerate(zip(means, stds, centroids)):\n",
    "        weight = np.concatenate([mean, std, centroid])\n",
    "        weights[index] = weight\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_new_graph(data):\n",
    "    graph = data['graph']\n",
    "    attribute = data['attributes']\n",
    "    nx.set_node_attributes(graph, attribute, name = 'features')\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attributes'] = df.progress_apply(construct_node_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['graph'] = df.progress_apply(construct_new_graph, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPINCS(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super(SPINCS, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout = 0.5)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads, dropout = 0.5)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p = 0.5, training = self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p = 0.5, training = self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SPINCS(8, args.hidden_channels, num_classes, args.heads).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.005, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(root='./cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cora()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[32]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dongjae_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c699c477c5c471d47a8de7a9cc4729800768f3401aa4bd1bfce7df4275c2064e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
